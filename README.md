# Toxic-comments-classification
This project focuses on classifying Wikipedia comments into six toxicity categories: Toxic, Severe Toxic, Obscene, Threat, Insult, and Identity Hate. The task is framed as a multilabel classification problem where a comment can belong to multiple categories. The project implements three neural architectures: BiLSTM, GRU, and BERT
